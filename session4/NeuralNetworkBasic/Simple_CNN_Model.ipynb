{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Modl\n",
        "- In this file we can simple Change the model Artitucture rest of the code will same to the previous file.\n",
        "- Simple Sequentail Model change to CNN Modle."
      ],
      "metadata": {
        "id": "jrJRZr7OONtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step\n",
        "- Get data\n",
        "- Build Model\n",
        "- Train Model\n",
        "- Evulate Model\n",
        "- Save the Model"
      ],
      "metadata": {
        "id": "0-70pFG6P7Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader # for data loading\n",
        "from torchvision import datasets # prebuild datasets\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor # Transformations"
      ],
      "metadata": {
        "id": "CXuFwqKWOuPQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "- We will use the prebuild dataset from troch so that we can train our custom model.\n",
        "- We will use the fashion Mnist Dataset which have 10 classes."
      ],
      "metadata": {
        "id": "VSrXMSvBO8N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we wil use pre build image net dataset\n",
        "train_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Test data\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "WfhxmglsQSGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428a1646-b41e-4ce7-a687-e78ffea86fb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 172kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.04MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 23.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjRG3ZQnQgIj",
        "outputId": "a92221a9-bf58-475b-e2fd-18e05160dbc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UubwQvp1RW08",
        "outputId": "47754862-b382-4ef4-ecc4-65c9945c004d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- we can get the data successfully.\n",
        "- Now we can make a dataloader so that we can load the data efficently."
      ],
      "metadata": {
        "id": "K_S88ptUR5Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Loader\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Test Loader\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LOh5QGlFSMOu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the barch\n",
        "for x, y in train_loader:\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Da6d5whSXoa",
        "outputId": "6974b262-4cec-499a-cc91-a91017d7f9ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model\n",
        "- Now we can build a CNN Model with 3 conv layers and 1 fully connected layers"
      ],
      "metadata": {
        "id": "vNHA4eokScKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32,kernel_size=3,padding=1,stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64,kernel_size=3,padding=1,stride=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128,kernel_size=3,padding=1,stride=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Flatten the layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(in_features=128*28*28, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "\n",
        "        x = self.relu(self.conv2(x))\n",
        "\n",
        "        x = self.relu(self.conv3(x))\n",
        "\n",
        "        x= self.flatten(x)\n",
        "\n",
        "        x= self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2SscGy-sSiT7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- We can make a simple CNN Model with `3 Conv layer` and `1 linear layer.`\n",
        "- Our Goal is not make the perfect model."
      ],
      "metadata": {
        "id": "0jjIfMd9Vyxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Optimizer and Loss\n",
        "model =MyCNN()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "model, loss_fn, optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI-LPVGfWCpo",
        "outputId": "b4123fbc-e0a5-4933-9997-14c66f9efde4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MyCNN(\n",
              "   (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "   (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "   (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "   (relu): ReLU()\n",
              "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "   (fc): Linear(in_features=100352, out_features=10, bias=True)\n",
              " ),\n",
              " CrossEntropyLoss(),\n",
              " SGD (\n",
              " Parameter Group 0\n",
              "     dampening: 0\n",
              "     differentiable: False\n",
              "     foreach: None\n",
              "     fused: None\n",
              "     lr: 0.0001\n",
              "     maximize: False\n",
              "     momentum: 0\n",
              "     nesterov: False\n",
              "     weight_decay: 0\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make Training Loop"
      ],
      "metadata": {
        "id": "rjAa3XPCWLWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xPvYbwj0Wzsw",
        "outputId": "ed07c147-e36a-483c-fd60-90be0c4288f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for image, label in tqdm(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        # Set the optimizer to zero_grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # do backward\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss +=loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _, prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    # calculate the accuracy\n",
        "    accuracy = num_correct/num_samples\n",
        "    print(f\"Epoch: {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfYpjBFkWqMd",
        "outputId": "7b4004b5-3580-42e9-ef53-0e86a3a3f5a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 97.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5, Train Loss: 2.2593, Train Accuracy: 35.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 115.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/5, Train Loss: 2.0110, Train Accuracy: 60.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:14<00:00, 126.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/5, Train Loss: 1.2047, Train Accuracy: 68.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:14<00:00, 125.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/5, Train Loss: 0.7828, Train Accuracy: 74.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:15<00:00, 123.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/5, Train Loss: 0.6829, Train Accuracy: 76.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "128*28*28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv-ARgEdmL1Q",
        "outputId": "bb68fb95-7931-4b14-a331-162f259ef872"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100352"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model Evulation"
      ],
      "metadata": {
        "id": "e-CHgndbYODA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for image, label in tqdm(test_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _,prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    accuracy = num_correct/num_samples\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5H06Q4eN7HW",
        "outputId": "d28f0da7-bdbc-47ce-ff56-59b133616103"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 154.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.6736, Test Accuracy: 76.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- We see that we can train the model in 5 epochs and we will get the 76% accuracy in this dataset with simple CNN model.\n",
        "- we will definetly improve the model"
      ],
      "metadata": {
        "id": "rZUDMfBtO33J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qep-NjrsXcm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}