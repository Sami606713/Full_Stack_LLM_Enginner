{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load Model\n",
        "- In this file we will see how we can save and load the **model checkpoint** that i can train.\n",
        "- We will see how we can save the best model."
      ],
      "metadata": {
        "id": "jrJRZr7OONtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step\n",
        "- Get data\n",
        "- Build Model\n",
        "- Train Model\n",
        "- Evulate Model\n",
        "- Save the Model"
      ],
      "metadata": {
        "id": "0-70pFG6P7Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader # for data loading\n",
        "from torchvision import datasets # prebuild datasets\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor # Transformations"
      ],
      "metadata": {
        "id": "CXuFwqKWOuPQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "- We will use the prebuild dataset from troch so that we can train our custom model.\n",
        "- We will use the fashion Mnist Dataset which have 10 classes."
      ],
      "metadata": {
        "id": "VSrXMSvBO8N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we wil use pre build image net dataset\n",
        "train_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Test data\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "WfhxmglsQSGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd31371-6aef-41ba-b657-b6a369fdf869"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 297kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.95MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjRG3ZQnQgIj",
        "outputId": "ac7a6536-c7bd-41f4-feda-da6a7456a0ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UubwQvp1RW08",
        "outputId": "b6a3ca0f-cc65-40f3-f126-8558a05c2d01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- we can get the data successfully.\n",
        "- Now we can make a dataloader so that we can load the data efficently."
      ],
      "metadata": {
        "id": "K_S88ptUR5Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Loader\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "# Test Loader\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "LOh5QGlFSMOu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the barch\n",
        "for x, y in train_loader:\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Da6d5whSXoa",
        "outputId": "8f69fc8e-1174-4dab-ff82-c9efd878d1f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model\n",
        "- Now we can build a CNN Model with 3 conv layers and 1 fully connected layers"
      ],
      "metadata": {
        "id": "vNHA4eokScKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCustomModel,self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_seq = nn.Sequential(\n",
        "            nn.Linear(28*28,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,10)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.flatten(x)\n",
        "        x= self.linear_seq(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2SscGy-sSiT7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- We can make a simple CNN Model with `3 Conv layer` and `1 linear layer.`\n",
        "- Our Goal is not make the perfect model."
      ],
      "metadata": {
        "id": "0jjIfMd9Vyxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Optimizer and Loss\n",
        "model = MyCustomModel()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "model, loss_fn, optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI-LPVGfWCpo",
        "outputId": "a4590488-2d5c-46c6-fba7-29349ecff38a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MyCustomModel(\n",
              "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "   (linear_seq): Sequential(\n",
              "     (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "     (1): ReLU()\n",
              "     (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "     (3): ReLU()\n",
              "     (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "   )\n",
              " ),\n",
              " CrossEntropyLoss(),\n",
              " SGD (\n",
              " Parameter Group 0\n",
              "     dampening: 0\n",
              "     differentiable: False\n",
              "     foreach: None\n",
              "     fused: None\n",
              "     lr: 0.0001\n",
              "     maximize: False\n",
              "     momentum: 0\n",
              "     nesterov: False\n",
              "     weight_decay: 0\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model Checkpoint\n",
        "- Now we can make a fun that can save the model checkpoint.\n",
        "- But we will notice only best model will be save on every epochs."
      ],
      "metadata": {
        "id": "0DAJ9pgtf_ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename=\"Best_Model.pth.tar\"):\n",
        "    print(f\"Saving Model checkoint {filename}\")\n",
        "    torch.save(state, filename)"
      ],
      "metadata": {
        "id": "F5U1hzrhf-4m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjhPkXLkf-tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "rjAa3XPCWLWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xPvYbwj0Wzsw",
        "outputId": "97465789-68d0-4107-9e7d-fa710c6b5187"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "epochs = 15\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    best_loss = float('inf')\n",
        "    for image, label in tqdm(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        # Set the optimizer to zero_grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # do backward\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss +=loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _, prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    # calculate the accuracy\n",
        "    accuracy = num_correct/num_samples\n",
        "\n",
        "    # Save best model checkpoint\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": best_loss,\n",
        "            \"accuracy\": accuracy,\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "    print(f\"Epoch: {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfYpjBFkWqMd",
        "outputId": "aa423c8a-03de-4794-9997-4e5db6afd2e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 95.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 1/15, Train Loss: 2.2952, Train Accuracy: 15.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 94.92it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 2/15, Train Loss: 2.2685, Train Accuracy: 22.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 96.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 3/15, Train Loss: 2.2428, Train Accuracy: 26.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 93.76it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 4/15, Train Loss: 2.2156, Train Accuracy: 33.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 94.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 5/15, Train Loss: 2.1853, Train Accuracy: 41.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 94.38it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 6/15, Train Loss: 2.1507, Train Accuracy: 48.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 95.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 7/15, Train Loss: 2.1106, Train Accuracy: 52.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:20<00:00, 92.84it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 8/15, Train Loss: 2.0642, Train Accuracy: 54.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 97.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 9/15, Train Loss: 2.0108, Train Accuracy: 56.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:22<00:00, 85.20it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 10/15, Train Loss: 1.9501, Train Accuracy: 58.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:19<00:00, 94.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 11/15, Train Loss: 1.8824, Train Accuracy: 59.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:23<00:00, 79.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 12/15, Train Loss: 1.8090, Train Accuracy: 60.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:22<00:00, 81.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 13/15, Train Loss: 1.7326, Train Accuracy: 60.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:24<00:00, 76.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 14/15, Train Loss: 1.6561, Train Accuracy: 61.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:22<00:00, 83.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model checkoint Best_Model.pth.tar\n",
            "Epoch: 15/15, Train Loss: 1.5822, Train Accuracy: 62.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model Evulation"
      ],
      "metadata": {
        "id": "e-CHgndbYODA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for image, label in tqdm(test_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _,prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    accuracy = num_correct/num_samples\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5H06Q4eN7HW",
        "outputId": "5e7b6df0-3156-4140-b8f6-e739ede44b80"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 151.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.5507, Test Accuracy: 61.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- Now we can load the model checkpoits and do prediction"
      ],
      "metadata": {
        "id": "rZUDMfBtO33J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the model"
      ],
      "metadata": {
        "id": "_qep-NjrsXcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initilize the model\n",
        "model = MyCustomModel()\n",
        "\n",
        "# Load the model state\n",
        "checkpoint = torch.load(\"/content/Best_Model.pth.tar\")\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])"
      ],
      "metadata": {
        "id": "aoFz6lKyDCyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1fb462-a00a-4320-cdee-5f12107c8b2b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-e31bed88a1eb>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/Best_Model.pth.tar\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Test Model Again on test data"
      ],
      "metadata": {
        "id": "YK7TJVWpms84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for image, label in tqdm(test_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _,prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    accuracy = num_correct/num_samples\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "DjtQcz9bDCvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c61e553b-9142-48c2-da20-4facf81847db"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:02<00:00, 145.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.5507, Test Accuracy: 61.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSzgpbVDm29n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}