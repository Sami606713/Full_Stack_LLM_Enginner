{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Basic\n",
        "- In this file we can tell the basics of neurak network.\n",
        "- Means that we can see how we can build our neural network."
      ],
      "metadata": {
        "id": "jrJRZr7OONtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step\n",
        "- Get data\n",
        "- Build Model\n",
        "- Train Model\n",
        "- Evulate Model\n",
        "- Save the Model"
      ],
      "metadata": {
        "id": "0-70pFG6P7Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader # for data loading\n",
        "from torchvision import datasets # prebuild datasets\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor # Transformations"
      ],
      "metadata": {
        "id": "CXuFwqKWOuPQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "- We will use the prebuild dataset from troch so that we can train our custom model.\n",
        "- We will use the fashion Mnist Dataset which have 10 classes."
      ],
      "metadata": {
        "id": "VSrXMSvBO8N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we wil use pre build image net dataset\n",
        "train_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Test data\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "WfhxmglsQSGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4173b3-dd7a-43a3-a9ad-aa8e81399e80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.85MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 4.36MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjRG3ZQnQgIj",
        "outputId": "526fe91e-789e-4d73-f3c6-61b844cd41cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UubwQvp1RW08",
        "outputId": "87377a40-0a3b-42bf-dc4a-41afe3feab3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- we can get the data successfully.\n",
        "- Now we can make a dataloader so that we can load the data efficently."
      ],
      "metadata": {
        "id": "K_S88ptUR5Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Loader\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "\n",
        "# Test Loader\n",
        "test_loader = DataLoader(test_data, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "LOh5QGlFSMOu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the barch\n",
        "for x, y in train_loader:\n",
        "    print(x.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Da6d5whSXoa",
        "outputId": "94314105-5de0-4b14-d8e9-32bd0e6401d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 1, 28, 28])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model\n",
        "- we know that cnn is best on image data.\n",
        "- But can make a simple Sequentail Model and domot use `CNN`.\n",
        "- After training the simle network we will clear about basic so we can make `CNN`\n",
        "- Get the data ==> `Flatten` the input.\n",
        "- Pass the `flatten input` to the `linear model`\n",
        "- Linear model with expect input shape and output shape.\n",
        "- In this our image will be the shape of 28*28 so our model input size will be 28*28 and output node will be depend on us.\n",
        "- **example** = `nn.Linear(28*28 ,512)`"
      ],
      "metadata": {
        "id": "vNHA4eokScKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCustomModel,self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_seq = nn.Sequential(\n",
        "            nn.Linear(28*28,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,10)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x= self.flatten(x)\n",
        "        x= self.linear_seq(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2SscGy-sSiT7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- We can make a simple Model with 2 hidden layer.\n",
        "- Our Goal is not make the perfect model."
      ],
      "metadata": {
        "id": "0jjIfMd9Vyxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Optimizer and Loss\n",
        "model = MyCustomModel()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "model, loss_fn, optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI-LPVGfWCpo",
        "outputId": "fe2aedcd-556f-4bf9-e689-5b9934e1506f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MyCustomModel(\n",
              "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "   (linear_seq): Sequential(\n",
              "     (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "     (1): ReLU()\n",
              "     (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "     (3): ReLU()\n",
              "     (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "   )\n",
              " ),\n",
              " CrossEntropyLoss(),\n",
              " SGD (\n",
              " Parameter Group 0\n",
              "     dampening: 0\n",
              "     differentiable: False\n",
              "     foreach: None\n",
              "     fused: None\n",
              "     lr: 0.0001\n",
              "     maximize: False\n",
              "     momentum: 0\n",
              "     nesterov: False\n",
              "     weight_decay: 0\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make Training Loop"
      ],
      "metadata": {
        "id": "rjAa3XPCWLWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xPvYbwj0Wzsw",
        "outputId": "bd9bb48c-4bde-49a9-c226-5f487814da0c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for image, label in tqdm(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        # Set the optimizer to zero_grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # do backward\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss +=loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _, prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    # calculate the accuracy\n",
        "    accuracy = num_correct/num_samples\n",
        "    print(f\"Epoch: {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfYpjBFkWqMd",
        "outputId": "216954b6-7e4e-4012-b7fa-80c17c79426f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:34<00:00, 220.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10, Train Loss: 2.2373, Train Accuracy: 19.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:34<00:00, 220.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/10, Train Loss: 2.0841, Train Accuracy: 42.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:33<00:00, 227.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/10, Train Loss: 1.8403, Train Accuracy: 53.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:34<00:00, 218.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/10, Train Loss: 1.5503, Train Accuracy: 57.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:33<00:00, 225.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/10, Train Loss: 1.3164, Train Accuracy: 61.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:34<00:00, 218.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6/10, Train Loss: 1.1551, Train Accuracy: 63.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:34<00:00, 220.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7/10, Train Loss: 1.0447, Train Accuracy: 65.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:33<00:00, 223.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8/10, Train Loss: 0.9667, Train Accuracy: 66.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:36<00:00, 207.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9/10, Train Loss: 0.9089, Train Accuracy: 67.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7500/7500 [00:34<00:00, 220.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/10, Train Loss: 0.8644, Train Accuracy: 68.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model Evulation"
      ],
      "metadata": {
        "id": "e-CHgndbYODA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for image, label in tqdm(test_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # do forward pass\n",
        "        output = model(image)\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = loss_fn(output,label)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _,prediction = output.max(1)\n",
        "        num_correct += (prediction == label).sum()\n",
        "        num_samples += prediction.size(0)\n",
        "\n",
        "    accuracy = num_correct/num_samples\n",
        "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5H06Q4eN7HW",
        "outputId": "64a93321-c22d-4c6c-d81a-5a78affe88d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:02<00:00, 447.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.8586, Test Accuracy: 67.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "- We see that we can train the model in 10 epochs and we will get the 67% accuracy in this dataset with simple sequential model."
      ],
      "metadata": {
        "id": "rZUDMfBtO33J"
      }
    }
  ]
}